{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from starter_code.visualize import visualize\n",
    "from starter_code.utils import load_case\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_floatx('float16')\n",
    "K.set_epsilon(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume, segmentation = load_case(123)\n",
    "X = volume.get_data()\n",
    "y = segmentation.get_data()\n",
    "\n",
    "IMG_WIDTH = X.shape[2]\n",
    "IMG_HEIGHT = X.shape[1]\n",
    "IMG_SLICES = X.shape[0]\n",
    "# X = np.expand_dims(X, 3)\n",
    "# y = tf.keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NeuralNetwork import *\n",
    "model = makeModel(IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, monitor='accuracy'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs'),\n",
    "    tf.keras.callbacks.ModelCheckpoint('saved_models/model1.h5', verbose=1, save_best_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-179 Train set, 180-209 val_set, 210-299 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_numbers = np.delete(np.arange(0, 209, 1), [158, 159, 160, 170, 202])\n",
    "case_numbers_val = case_numbers[179:]\n",
    "case_numbers_train = case_numbers[:179]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "0003: val_loss did not improve from 0.00299\n103/103 [==============================] - 11s 108ms/sample - loss: 0.0047 - accuracy: 0.9985 - val_loss: 0.0124 - val_accuracy: 0.9971\nEpoch 4/4\n 96/103 [==========================>...] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\nEpoch 00004: val_loss did not improve from 0.00299\n103/103 [==============================] - 11s 108ms/sample - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0103 - val_accuracy: 0.9973\n\n\n\n\n 82%|████████▏ | 68/83 [1:01:50<18:04, 72.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 167 as train data\n\nloaded case 208 as validation data\nTrain on 103 samples, validate on 89 samples\nEpoch 1/4\n 96/103 [==========================>...] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\nEpoch 00001: val_loss did not improve from 0.00299\n103/103 [==============================] - 5s 48ms/sample - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0067 - val_accuracy: 0.9987\nEpoch 2/4\n 96/103 [==========================>...] - ETA: 0s - loss: 8.6348e-04 - accuracy: 0.9998\nEpoch 00002: val_loss did not improve from 0.00299\n103/103 [==============================] - 5s 47ms/sample - loss: 9.3316e-04 - accuracy: 0.9997 - val_loss: 0.0057 - val_accuracy: 0.9990\nEpoch 3/4\n 96/103 [==========================>...] - ETA: 0s - loss: 8.4879e-04 - accuracy: 0.9998\nEpoch 00003: val_loss did not improve from 0.00299\n103/103 [==============================] - 5s 46ms/sample - loss: 9.1027e-04 - accuracy: 0.9997 - val_loss: 0.0060 - val_accuracy: 0.9989\nEpoch 4/4\n 96/103 [==========================>...] - ETA: 0s - loss: 7.6944e-04 - accuracy: 0.9998\nEpoch 00004: val_loss did not improve from 0.00299\n103/103 [==============================] - 5s 49ms/sample - loss: 8.7420e-04 - accuracy: 0.9997 - val_loss: 0.0059 - val_accuracy: 0.9990\n\n\n\n\n 83%|████████▎ | 69/83 [1:02:14<13:29, 57.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 168 as train data\n\nloaded case 193 as validation data\nTrain on 83 samples, validate on 233 samples\nEpoch 1/4\n80/83 [===========================>..] - ETA: 0s - loss: 0.0055 - accuracy: 0.9987\nEpoch 00001: val_loss did not improve from 0.00299\n83/83 [==============================] - 6s 70ms/sample - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0035 - val_accuracy: 0.9988\nEpoch 2/4\n80/83 [===========================>..] - ETA: 0s - loss: 0.0039 - accuracy: 0.9989\nEpoch 00002: val_loss did not improve from 0.00299\n83/83 [==============================] - 6s 69ms/sample - loss: 0.0038 - accuracy: 0.9989 - val_loss: 0.0096 - val_accuracy: 0.9960\nEpoch 3/4\n80/83 [===========================>..] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\nEpoch 00003: val_loss did not improve from 0.00299\n83/83 [==============================] - 6s 70ms/sample - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0130 - val_accuracy: 0.9951\nEpoch 4/4\n80/83 [===========================>..] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\nEpoch 00004: val_loss did not improve from 0.00299\n83/83 [==============================] - 6s 74ms/sample - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0092 - val_accuracy: 0.9963\n\n\n\n\n 84%|████████▍ | 70/83 [1:02:44<10:43, 49.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 169 as train data\n\nloaded case 192 as validation data\nTrain on 101 samples, validate on 133 samples\nEpoch 1/4\n 96/101 [===========================>..] - ETA: 0s - loss: 0.0043 - accuracy: 0.9986\nEpoch 00001: val_loss did not improve from 0.00299\n101/101 [==============================] - 5s 54ms/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0592 - val_accuracy: 0.9913\nEpoch 2/4\n 96/101 [===========================>..] - ETA: 0s - loss: 0.0028 - accuracy: 0.9991\nEpoch 00002: val_loss did not improve from 0.00299\n101/101 [==============================] - 5s 54ms/sample - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0689 - val_accuracy: 0.9915\nEpoch 3/4\n 96/101 [===========================>..] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\nEpoch 00003: val_loss did not improve from 0.00299\n101/101 [==============================] - 5s 53ms/sample - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0665 - val_accuracy: 0.9918\nEpoch 4/4\n 96/101 [===========================>..] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\nEpoch 00004: val_loss did not improve from 0.00299\n101/101 [==============================] - 5s 53ms/sample - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0686 - val_accuracy: 0.9919\n\n\n\n\n 86%|████████▌ | 71/83 [1:03:11<08:30, 42.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 171 as train data\n\nloaded case 208 as validation data\nTrain on 131 samples, validate on 89 samples\nEpoch 1/4\n128/131 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9984\nEpoch 00001: val_loss did not improve from 0.00299\n131/131 [==============================] - 6s 46ms/sample - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0074 - val_accuracy: 0.9983\nEpoch 2/4\n128/131 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9992\nEpoch 00002: val_loss did not improve from 0.00299\n131/131 [==============================] - 6s 46ms/sample - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0078 - val_accuracy: 0.9984\nEpoch 3/4\n128/131 [============================>.] - ETA: 0s - loss: 0.0018 - accuracy: 0.9994\nEpoch 00003: val_loss did not improve from 0.00299\n131/131 [==============================] - 6s 44ms/sample - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0071 - val_accuracy: 0.9986\nEpoch 4/4\n128/131 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\nEpoch 00004: val_loss did not improve from 0.00299\n131/131 [==============================] - 6s 44ms/sample - loss: 0.0016 - accuracy: 0.9994 - val_loss: 0.0077 - val_accuracy: 0.9985\n\n\n\n\n 87%|████████▋ | 72/83 [1:03:40<07:04, 38.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 172 as train data\n\nloaded case 186 as validation data\nTrain on 91 samples, validate on 143 samples\nEpoch 1/4\n88/91 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9935\nEpoch 00001: val_loss did not improve from 0.00299\n91/91 [==============================] - 5s 58ms/sample - loss: 0.0222 - accuracy: 0.9937 - val_loss: 0.0369 - val_accuracy: 0.9930\nEpoch 2/4\n88/91 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9949\nEpoch 00002: val_loss did not improve from 0.00299\n91/91 [==============================] - 5s 55ms/sample - loss: 0.0165 - accuracy: 0.9949 - val_loss: 0.0264 - val_accuracy: 0.9931\nEpoch 3/4\n88/91 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9954\nEpoch 00003: val_loss did not improve from 0.00299\n91/91 [==============================] - 5s 55ms/sample - loss: 0.0120 - accuracy: 0.9955 - val_loss: 0.0254 - val_accuracy: 0.9951\nEpoch 4/4\n88/91 [============================>.] - ETA: 0s - loss: 0.0089 - accuracy: 0.9966\nEpoch 00004: val_loss did not improve from 0.00299\n91/91 [==============================] - 5s 56ms/sample - loss: 0.0091 - accuracy: 0.9965 - val_loss: 0.0324 - val_accuracy: 0.9936\n\n\n\n\n 88%|████████▊ | 73/83 [1:04:05<05:46, 34.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 173 as train data\n\nloaded case 196 as validation data\nTrain on 97 samples, validate on 178 samples\nEpoch 1/4\n96/97 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9987\nEpoch 00001: val_loss improved from 0.00299 to 0.00244, saving model to saved_models/model1.h5\n97/97 [==============================] - 6s 65ms/sample - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0024 - val_accuracy: 0.9993\nEpoch 2/4\n96/97 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9994\nEpoch 00002: val_loss did not improve from 0.00244\n97/97 [==============================] - 6s 58ms/sample - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0030 - val_accuracy: 0.9993\nEpoch 3/4\n96/97 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9996\nEpoch 00003: val_loss improved from 0.00244 to 0.00237, saving model to saved_models/model1.h5\n97/97 [==============================] - 6s 61ms/sample - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0024 - val_accuracy: 0.9994\nEpoch 4/4\n96/97 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9996\nEpoch 00004: val_loss improved from 0.00237 to 0.00234, saving model to saved_models/model1.h5\n97/97 [==============================] - 6s 59ms/sample - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0023 - val_accuracy: 0.9994\n\n\n\n\n 89%|████████▉ | 74/83 [1:04:35<04:57, 33.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 174 as train data\n\nloaded case 190 as validation data\nTrain on 69 samples, validate on 161 samples\nEpoch 1/4\n64/69 [==========================>...] - ETA: 0s - loss: 0.0036 - accuracy: 0.9989\nEpoch 00001: val_loss did not improve from 0.00234\n69/69 [==============================] - 5s 66ms/sample - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.0105 - val_accuracy: 0.9986\nEpoch 2/4\n64/69 [==========================>...] - ETA: 0s - loss: 0.0033 - accuracy: 0.9991\nEpoch 00002: val_loss did not improve from 0.00234\n69/69 [==============================] - 4s 64ms/sample - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0103 - val_accuracy: 0.9987\nEpoch 3/4\n64/69 [==========================>...] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\nEpoch 00003: val_loss did not improve from 0.00234\n69/69 [==============================] - 4s 64ms/sample - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0107 - val_accuracy: 0.9986\nEpoch 4/4\n64/69 [==========================>...] - ETA: 0s - loss: 0.0028 - accuracy: 0.9992\nEpoch 00004: val_loss did not improve from 0.00234\n69/69 [==============================] - 4s 63ms/sample - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0107 - val_accuracy: 0.9987\n\n\n\n\n 90%|█████████ | 75/83 [1:04:58<03:59, 29.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 175 as train data\n\nloaded case 196 as validation data\nTrain on 107 samples, validate on 178 samples\nEpoch 1/4\n104/107 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9991\nEpoch 00001: val_loss did not improve from 0.00234\n107/107 [==============================] - 6s 56ms/sample - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0046 - val_accuracy: 0.9989\nEpoch 2/4\n104/107 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9995\nEpoch 00002: val_loss did not improve from 0.00234\n107/107 [==============================] - 6s 56ms/sample - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9991\nEpoch 3/4\n104/107 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\nEpoch 00003: val_loss did not improve from 0.00234\n107/107 [==============================] - 6s 56ms/sample - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9991\nEpoch 4/4\n104/107 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9995\nEpoch 00004: val_loss did not improve from 0.00234\n107/107 [==============================] - 6s 55ms/sample - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9992\n\n\n\n\n 92%|█████████▏| 76/83 [1:05:27<03:29, 29.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 176 as train data\n\nloaded case 185 as validation data\nTrain on 102 samples, validate on 235 samples\nEpoch 1/4\n 96/102 [===========================>..] - ETA: 0s - loss: 0.0143 - accuracy: 0.9975\nEpoch 00001: val_loss did not improve from 0.00234\n102/102 [==============================] - 7s 64ms/sample - loss: 0.0138 - accuracy: 0.9975 - val_loss: 0.0054 - val_accuracy: 0.9987\nEpoch 2/4\n 96/102 [===========================>..] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\nEpoch 00002: val_loss did not improve from 0.00234\n102/102 [==============================] - 6s 63ms/sample - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0078 - val_accuracy: 0.9983\nEpoch 3/4\n 96/102 [===========================>..] - ETA: 0s - loss: 0.0020 - accuracy: 0.9993\nEpoch 00003: val_loss did not improve from 0.00234\n102/102 [==============================] - 6s 63ms/sample - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0097 - val_accuracy: 0.9979\nEpoch 4/4\n 96/102 [===========================>..] - ETA: 0s - loss: 0.0017 - accuracy: 0.9994\nEpoch 00004: val_loss did not improve from 0.00234\n102/102 [==============================] - 6s 63ms/sample - loss: 0.0017 - accuracy: 0.9994 - val_loss: 0.0123 - val_accuracy: 0.9976\n\n\n\n\n 93%|█████████▎| 77/83 [1:06:01<03:06, 31.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 177 as train data\n\nloaded case 200 as validation data\nTrain on 88 samples, validate on 103 samples\nEpoch 1/4\n80/88 [==========================>...] - ETA: 0s - loss: 0.0178 - accuracy: 0.9967\nEpoch 00001: val_loss did not improve from 0.00234\n88/88 [==============================] - 4s 51ms/sample - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0200 - val_accuracy: 0.9942\nEpoch 2/4\n80/88 [==========================>...] - ETA: 0s - loss: 0.0068 - accuracy: 0.9977\nEpoch 00002: val_loss did not improve from 0.00234\n88/88 [==============================] - 4s 51ms/sample - loss: 0.0068 - accuracy: 0.9977 - val_loss: 0.0104 - val_accuracy: 0.9963\nEpoch 3/4\n80/88 [==========================>...] - ETA: 0s - loss: 0.0042 - accuracy: 0.9986\nEpoch 00003: val_loss did not improve from 0.00234\n88/88 [==============================] - 4s 51ms/sample - loss: 0.0042 - accuracy: 0.9986 - val_loss: 0.0131 - val_accuracy: 0.9963\nEpoch 4/4\n80/88 [==========================>...] - ETA: 0s - loss: 0.0033 - accuracy: 0.9988\nEpoch 00004: val_loss did not improve from 0.00234\n88/88 [==============================] - 4s 51ms/sample - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.0165 - val_accuracy: 0.9964\n\n\n\n\n 94%|█████████▍| 78/83 [1:06:24<02:23, 28.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 178 as train data\n\nloaded case 187 as validation data\nTrain on 88 samples, validate on 82 samples\nEpoch 1/4\n80/88 [==========================>...] - ETA: 0s - loss: 0.0400 - accuracy: 0.9944\nEpoch 00001: val_loss did not improve from 0.00234\n88/88 [==============================] - 4s 49ms/sample - loss: 0.0394 - accuracy: 0.9942 - val_loss: 0.0617 - val_accuracy: 0.9843\nEpoch 2/4\n80/88 [==========================>...] - ETA: 0s - loss: 0.0147 - accuracy: 0.9959\nEpoch 00002: val_loss did not improve from 0.00234\n88/88 [==============================] - 4s 49ms/sample - loss: 0.0147 - accuracy: 0.9959 - val_loss: 0.0664 - val_accuracy: 0.9803\nEpoch 3/4\n80/88 [==========================>...] - ETA: 0s - loss: 0.0096 - accuracy: 0.9969\nEpoch 00003: val_loss did not improve from 0.00234\n88/88 [==============================] - 4s 48ms/sample - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.0381 - val_accuracy: 0.9916\nEpoch 4/4\n80/88 [==========================>...] - ETA: 0s - loss: 0.0059 - accuracy: 0.9981\nEpoch 00004: val_loss did not improve from 0.00234\n88/88 [==============================] - 4s 48ms/sample - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.0373 - val_accuracy: 0.9908\n\n\n\n\n 95%|█████████▌| 79/83 [1:06:46<01:46, 26.52s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 179 as train data\n\nloaded case 204 as validation data\nTrain on 99 samples, validate on 75 samples\nEpoch 1/4\n96/99 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9961\nEpoch 00001: val_loss did not improve from 0.00234\n99/99 [==============================] - 5s 47ms/sample - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.0139 - val_accuracy: 0.9952\nEpoch 2/4\n96/99 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9978\nEpoch 00002: val_loss did not improve from 0.00234\n99/99 [==============================] - 5s 46ms/sample - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.0191 - val_accuracy: 0.9959\nEpoch 3/4\n96/99 [============================>.] - ETA: 0s - loss: 0.0051 - accuracy: 0.9984\nEpoch 00003: val_loss did not improve from 0.00234\n99/99 [==============================] - 5s 47ms/sample - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0183 - val_accuracy: 0.9960\nEpoch 4/4\n96/99 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987\nEpoch 00004: val_loss did not improve from 0.00234\n99/99 [==============================] - 5s 46ms/sample - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.0221 - val_accuracy: 0.9945\n\n\n\n\n 96%|█████████▋| 80/83 [1:07:08<01:15, 25.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 180 as train data\n\nloaded case 203 as validation data\nTrain on 137 samples, validate on 620 samples\nEpoch 1/4\n136/137 [============================>.] - ETA: 0s - loss: 0.0806 - accuracy: 0.9927\nEpoch 00001: val_loss did not improve from 0.00234\n137/137 [==============================] - 12s 90ms/sample - loss: 0.0800 - accuracy: 0.9928 - val_loss: 0.0170 - val_accuracy: 0.9983\nEpoch 2/4\n136/137 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9961\nEpoch 00002: val_loss did not improve from 0.00234\n137/137 [==============================] - 12s 89ms/sample - loss: 0.0153 - accuracy: 0.9961 - val_loss: 0.0205 - val_accuracy: 0.9977\nEpoch 3/4\n136/137 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9981\nEpoch 00003: val_loss did not improve from 0.00234\n137/137 [==============================] - 12s 91ms/sample - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0240 - val_accuracy: 0.9979\nEpoch 4/4\n136/137 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9987\nEpoch 00004: val_loss did not improve from 0.00234\n137/137 [==============================] - 12s 90ms/sample - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0231 - val_accuracy: 0.9979\n\n\n\n\n 98%|█████████▊| 81/83 [1:08:15<01:15, 37.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 181 as train data\n\nloaded case 197 as validation data\nTrain on 99 samples, validate on 162 samples\nEpoch 1/4\n96/99 [============================>.] - ETA: 0s - loss: 0.0626 - accuracy: 0.9899\nEpoch 00001: val_loss did not improve from 0.00234\n99/99 [==============================] - 6s 58ms/sample - loss: 0.0624 - accuracy: 0.9899 - val_loss: 0.0287 - val_accuracy: 0.9926\nEpoch 2/4\n96/99 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9953\nEpoch 00002: val_loss did not improve from 0.00234\n99/99 [==============================] - 6s 59ms/sample - loss: 0.0149 - accuracy: 0.9953 - val_loss: 0.0350 - val_accuracy: 0.9908\nEpoch 3/4\n96/99 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9962\nEpoch 00003: val_loss did not improve from 0.00234\n99/99 [==============================] - 6s 59ms/sample - loss: 0.0108 - accuracy: 0.9963 - val_loss: 0.0373 - val_accuracy: 0.9917\nEpoch 4/4\n96/99 [============================>.] - ETA: 0s - loss: 0.0070 - accuracy: 0.9977\nEpoch 00004: val_loss did not improve from 0.00234\n99/99 [==============================] - 6s 58ms/sample - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0425 - val_accuracy: 0.9916\n\n\n\n\n 99%|█████████▉| 82/83 [1:08:44<00:35, 35.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\nloaded case 182 as train data\n\nloaded case 198 as validation data\nTrain on 93 samples, validate on 269 samples\nEpoch 1/4\n88/93 [===========================>..] - ETA: 0s - loss: 0.0184 - accuracy: 0.9942\nEpoch 00001: val_loss did not improve from 0.00234\n93/93 [==============================] - 7s 74ms/sample - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.0052 - val_accuracy: 0.9986\nEpoch 2/4\n88/93 [===========================>..] - ETA: 0s - loss: 0.0045 - accuracy: 0.9987\nEpoch 00002: val_loss did not improve from 0.00234\n93/93 [==============================] - 7s 76ms/sample - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0046 - val_accuracy: 0.9989\nEpoch 3/4\n88/93 [===========================>..] - ETA: 0s - loss: 0.0025 - accuracy: 0.9994\nEpoch 00003: val_loss did not improve from 0.00234\n93/93 [==============================] - 7s 73ms/sample - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9990\nEpoch 4/4\n88/93 [===========================>..] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\nEpoch 00004: val_loss did not improve from 0.00234\n93/93 [==============================] - 7s 73ms/sample - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0039 - val_accuracy: 0.9991\n\n\n\n\n100%|██████████| 83/83 [1:09:20<00:00, 50.12s/it]\n"
    }
   ],
   "source": [
    "for n_img in tqdm(case_numbers_train[96:]):    \n",
    "    volume, segmentation = load_case(n_img)\n",
    "    X = volume.get_data()\n",
    "    y = segmentation.get_data()\n",
    "    X = np.expand_dims(X, 3)\n",
    "    y = tf.keras.utils.to_categorical(y)\n",
    "    print('\\nloaded case {} as train data'.format(n_img))\n",
    "    random_val_index = case_numbers_val[np.random.randint(0, len(case_numbers_val))]\n",
    "    volume_val, segmentation_val = load_case(random_val_index)\n",
    "    X_val = volume_val.get_data()\n",
    "    y_val = segmentation_val.get_data()\n",
    "    X_val = np.expand_dims(X_val, 3)\n",
    "    y_val = tf.keras.utils.to_categorical(y_val)\n",
    "    print('\\nloaded case {} as validation data'.format(random_val_index))\n",
    "    results = model.fit(X, y, batch_size=8, epochs=4, callbacks=callbacks, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: saved_models\\model_big_3\\assets\n"
    }
   ],
   "source": [
    "model.save('saved_models\\model_big_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score(y_pred, y_test):\n",
    "    return np.sum(y_pred)*2.0 / (np.sum(y_pred) + np.sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9818619323782505"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "dice_score(predicted[:,:,:,1], y[:,:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "from visualizeSlider import *\n",
    "cube_show_slider(cube=predicted[:,:,:,2], axis=0, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# volume, segmentation = load_case(123)\n",
    "# X = volume.get_data()\n",
    "# X = np.expand_dims(X, 3)\n",
    "# model = tf.keras.models.load_model('model_big_1')\n",
    "\n",
    "# print(segmentation.shape)\n",
    "# nifty = nib.Nifti1Image(segmentation, volume.affine, volume.header)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}