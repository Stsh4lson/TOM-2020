{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from starter_code.visualize import visualize\n",
    "from starter_code.utils import load_case\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume, segmentation = load_case(123)\n",
    "X = volume.get_data()\n",
    "y = segmentation.get_data()\n",
    "\n",
    "IMG_WIDTH = X.shape[2]\n",
    "IMG_HEIGHT = X.shape[1]\n",
    "IMG_SLICES = X.shape[0]\n",
    "X = np.expand_dims(X, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralNetwork import *\n",
    "model = makeModel(IMG_WIDTH, IMG_HEIGHT, 1)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 350 samples, validate on 39 samples\nEpoch 1/25\n350/350 [==============================] - 23s 66ms/sample - loss: 0.0486 - accuracy: 0.9892 - val_loss: 0.0146 - val_accuracy: 1.0000\nEpoch 2/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0158 - accuracy: 0.9958 - val_loss: 0.0176 - val_accuracy: 1.0000\nEpoch 3/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0137 - accuracy: 0.9958 - val_loss: 0.0058 - val_accuracy: 1.0000\nEpoch 4/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0086 - accuracy: 0.9959 - val_loss: 0.0015 - val_accuracy: 1.0000\nEpoch 5/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0062 - accuracy: 0.9965 - val_loss: 0.0010 - val_accuracy: 1.0000\nEpoch 6/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0048 - accuracy: 0.9971 - val_loss: 2.0801e-04 - val_accuracy: 1.0000\nEpoch 7/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0042 - accuracy: 0.9983 - val_loss: 3.1334e-04 - val_accuracy: 1.0000\nEpoch 8/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0035 - accuracy: 0.9990 - val_loss: 1.9017e-04 - val_accuracy: 1.0000\nEpoch 9/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 6.1050e-05 - val_accuracy: 1.0000\nEpoch 10/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0010 - accuracy: 0.9996 - val_loss: 1.8204e-05 - val_accuracy: 1.0000\nEpoch 11/25\n350/350 [==============================] - 13s 37ms/sample - loss: 7.5413e-04 - accuracy: 0.9997 - val_loss: 2.3611e-05 - val_accuracy: 1.0000\nEpoch 12/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0076 - val_accuracy: 0.9971\nEpoch 13/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0045 - val_accuracy: 0.9982\nEpoch 14/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0090 - val_accuracy: 0.9972\nEpoch 15/25\n350/350 [==============================] - 13s 37ms/sample - loss: 0.0010 - accuracy: 0.9996 - val_loss: 0.0140 - val_accuracy: 0.9972\n"
    }
   ],
   "source": [
    "checkpointer = tf.keras.callbacks.ModelCheckpoint('model1.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='logs')\n",
    "]\n",
    "results = model.fit(X, y, validation_split=0.1, batch_size=16, epochs=25, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[[[1.79516992e-05]\n   [1.88722615e-09]\n   [1.42892764e-11]\n   ...\n   [3.54119078e-12]\n   [2.42995152e-14]\n   [1.62781873e-06]]\n\n  [[1.28180784e-06]\n   [1.62568842e-15]\n   [2.04126752e-20]\n   ...\n   [1.33808485e-25]\n   [7.17946980e-23]\n   [7.76389647e-11]]\n\n  [[1.06488605e-08]\n   [7.20442260e-19]\n   [7.30636502e-24]\n   ...\n   [1.75412333e-31]\n   [1.42330710e-27]\n   [9.02115152e-18]]\n\n  ...\n\n  [[6.01524386e-10]\n   [1.35568422e-22]\n   [9.75057963e-26]\n   ...\n   [8.86135488e-34]\n   [7.18508586e-23]\n   [1.87337532e-17]]\n\n  [[1.25796959e-07]\n   [7.20303605e-15]\n   [1.09712465e-16]\n   ...\n   [3.67892631e-28]\n   [2.70589522e-17]\n   [1.72461681e-13]]\n\n  [[5.56969053e-06]\n   [9.96629862e-12]\n   [9.85384625e-13]\n   ...\n   [2.61529798e-19]\n   [5.50343815e-09]\n   [1.42575132e-10]]]\n\n\n [[[1.79516828e-05]\n   [1.88722260e-09]\n   [1.42893024e-11]\n   ...\n   [3.54116411e-12]\n   [2.42996083e-14]\n   [1.62781396e-06]]\n\n  [[1.28180898e-06]\n   [1.62568842e-15]\n   [2.04125977e-20]\n   ...\n   [1.33807980e-25]\n   [7.17941426e-23]\n   [7.76389647e-11]]\n\n  [[1.06487796e-08]\n   [7.20442260e-19]\n   [7.30642024e-24]\n   ...\n   [1.75411005e-31]\n   [1.42330710e-27]\n   [9.02111596e-18]]\n\n  ...\n\n  [[6.01522110e-10]\n   [1.35567387e-22]\n   [9.75054142e-26]\n   ...\n   [8.86121896e-34]\n   [7.18503095e-23]\n   [1.87336805e-17]]\n\n  [[1.25796831e-07]\n   [7.20300894e-15]\n   [1.09712882e-16]\n   ...\n   [3.67891234e-28]\n   [2.70589522e-17]\n   [1.72461356e-13]]\n\n  [[5.56968007e-06]\n   [9.96626046e-12]\n   [9.85386469e-13]\n   ...\n   [2.61530780e-19]\n   [5.50340618e-09]\n   [1.42575132e-10]]]\n\n\n [[[1.79516483e-05]\n   [1.88721905e-09]\n   [1.42893024e-11]\n   ...\n   [3.54119078e-12]\n   [2.42995152e-14]\n   [1.62781566e-06]]\n\n  [[1.28180784e-06]\n   [1.62568842e-15]\n   [2.04126752e-20]\n   ...\n   [1.33808485e-25]\n   [7.17946980e-23]\n   [7.76389647e-11]]\n\n  [[1.06488205e-08]\n   [7.20439469e-19]\n   [7.30642024e-24]\n   ...\n   [1.75412333e-31]\n   [1.42331250e-27]\n   [9.02101338e-18]]\n\n  ...\n\n  [[6.01523276e-10]\n   [1.35567387e-22]\n   [9.75054142e-26]\n   ...\n   [8.86128692e-34]\n   [7.18505872e-23]\n   [1.87336805e-17]]\n\n  [[1.25797200e-07]\n   [7.20303605e-15]\n   [1.09713736e-16]\n   ...\n   [3.67892631e-28]\n   [2.70588480e-17]\n   [1.72461681e-13]]\n\n  [[5.56969599e-06]\n   [9.96629862e-12]\n   [9.85390263e-13]\n   ...\n   [2.61532770e-19]\n   [5.50342749e-09]\n   [1.42575673e-10]]]\n\n\n ...\n\n\n [[[1.79516646e-05]\n   [1.88721549e-09]\n   [1.42893293e-11]\n   ...\n   [3.54119078e-12]\n   [2.42995152e-14]\n   [1.62781566e-06]]\n\n  [[1.28180784e-06]\n   [1.62568842e-15]\n   [2.04125977e-20]\n   ...\n   [1.33807980e-25]\n   [7.17946980e-23]\n   [7.76388190e-11]]\n\n  [[1.06487796e-08]\n   [7.20436780e-19]\n   [7.30633741e-24]\n   ...\n   [1.75412333e-31]\n   [1.42331250e-27]\n   [9.02111596e-18]]\n\n  ...\n\n  [[6.01520944e-10]\n   [1.35566870e-22]\n   [9.75050506e-26]\n   ...\n   [8.86148988e-34]\n   [7.18516790e-23]\n   [1.87337532e-17]]\n\n  [[1.25797314e-07]\n   [7.20303605e-15]\n   [1.09712465e-16]\n   ...\n   [3.67896868e-28]\n   [2.70592632e-17]\n   [1.72462007e-13]]\n\n  [[5.56968007e-06]\n   [9.96627867e-12]\n   [9.85380939e-13]\n   ...\n   [2.61533753e-19]\n   [5.50346968e-09]\n   [1.42576478e-10]]]\n\n\n [[[1.79516646e-05]\n   [1.88721905e-09]\n   [1.42893293e-11]\n   ...\n   [3.54119078e-12]\n   [2.42995626e-14]\n   [1.62781396e-06]]\n\n  [[1.28180648e-06]\n   [1.62568842e-15]\n   [2.04126752e-20]\n   ...\n   [1.33809003e-25]\n   [7.17946980e-23]\n   [7.76388190e-11]]\n\n  [[1.06488001e-08]\n   [7.20442260e-19]\n   [7.30639263e-24]\n   ...\n   [1.75412333e-31]\n   [1.42331250e-27]\n   [9.02118627e-18]]\n\n  ...\n\n  [[6.01518668e-10]\n   [1.35565330e-22]\n   [9.75035592e-26]\n   ...\n   [8.86128692e-34]\n   [7.18511299e-23]\n   [1.87337532e-17]]\n\n  [[1.25797072e-07]\n   [7.20298099e-15]\n   [1.09711215e-16]\n   ...\n   [3.67892631e-28]\n   [2.70591590e-17]\n   [1.72461681e-13]]\n\n  [[5.56968507e-06]\n   [9.96618413e-12]\n   [9.85375301e-13]\n   ...\n   [2.61533753e-19]\n   [5.50345902e-09]\n   [1.42576215e-10]]]\n\n\n [[[1.79516646e-05]\n   [1.88721905e-09]\n   [1.42893562e-11]\n   ...\n   [3.54118427e-12]\n   [2.42995626e-14]\n   [1.62781259e-06]]\n\n  [[1.28180784e-06]\n   [1.62568842e-15]\n   [2.04125977e-20]\n   ...\n   [1.33807980e-25]\n   [7.17946980e-23]\n   [7.76389647e-11]]\n\n  [[1.06488001e-08]\n   [7.20439469e-19]\n   [7.30639263e-24]\n   ...\n   [1.75412333e-31]\n   [1.42332347e-27]\n   [9.02125492e-18]]\n\n  ...\n\n  [[6.01516337e-10]\n   [1.35564800e-22]\n   [9.75024437e-26]\n   ...\n   [8.86128692e-34]\n   [7.18508586e-23]\n   [1.87337532e-17]]\n\n  [[1.25796348e-07]\n   [7.20289883e-15]\n   [1.09710798e-16]\n   ...\n   [3.67896868e-28]\n   [2.70589522e-17]\n   [1.72461031e-13]]\n\n  [[5.56964778e-06]\n   [9.96610780e-12]\n   [9.85365869e-13]\n   ...\n   [2.61534761e-19]\n   [5.50342749e-09]\n   [1.42575396e-10]]]]\n"
    }
   ],
   "source": [
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "from visualizeSlider import *\n",
    "cube_show_slider(cube=predicted[:,:,:,0], axis=0, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}